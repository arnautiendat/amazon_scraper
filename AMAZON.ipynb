{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "#Revisant robots.txt es veu sobre quines pagines no es pot fer scrapping. \n",
    "import urllib.robotparser\n",
    "rp = urllib.robotparser.RobotFileParser()\n",
    "rp.set_url('http://www.amazon.com/robots.txt')\n",
    "rp.read()\n",
    "url = 'https://www.amazon.es/gp/bestsellers/books?pf_rd_r=3SGMV0M1FJ0N0CB7MQC0&pf_rd_p=d3259a28-7b77-56ff-ade0-8a02db82407a&pd_rd_r=0c54ad8c-b4d5-4d1a-a3bb-3246e048bdc2&pd_rd_w=m1O3G&pd_rd_wg=ES5Zj&ref_=pd_gw_ri'\n",
    "user_agent = 'wswp'\n",
    "print(rp.can_fetch(user_agent, url))\n",
    "\n",
    "#Es declara la variable on s'enmagatzemaran els resultats\n",
    "\n",
    "llista_llibres = []\n",
    "\n",
    "#Es crea l'scrapp\n",
    "#El llistat de llibres de Amazon es divideix en dues pagines, pel que hem de llegir aquestes dues.\n",
    "for pagina in range(1,3):\n",
    "    url = \"https://www.amazon.es/gp/bestsellers/books/ref=zg_bs_pg_1/259-0380097-5900722?ie=UTF8&pg=%d\" % pagina\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content)\n",
    "\n",
    "    # Guardem en la variable llistat el contingut de tots els llibres\n",
    "    llistat = soup.find(class_=\"a-ordered-list a-vertical\")\n",
    "\n",
    "    # Recorrem llibre a llibre (aok-inline-block zg-item) buscant les característiques de cada un d'ells. S'Afegeix \n",
    "    #la opció NULL en cas de que la característica no estigui documentada.\n",
    "\n",
    "    for descripcio in llistat.find_all('span', class_=\"aok-inline-block zg-item\"):\n",
    "    \n",
    "        nom = (descripcio.find(class_=\"p13n-sc-truncate\").string).strip()\n",
    "        try:\n",
    "            autor = descripcio.find(class_=\"a-row a-size-small\").string\n",
    "        except:\n",
    "            autor = \"NULL\"\n",
    "        try:\n",
    "            puntuacio = descripcio.find(class_=\"a-icon-alt\").string\n",
    "        except:\n",
    "            puntacio = \"NULL\"\n",
    "        try:\n",
    "            num_resenyes = descripcio.find(class_=\"a-size-small a-link-normal\").string\n",
    "        except: \n",
    "            num_resenyes = \"NULL\"\n",
    "        try:\n",
    "            categoria = descripcio.find(class_=\"a-size-small a-color-secondary\").string\n",
    "        except:\n",
    "            categoria = \"NULL\"\n",
    "        preu = descripcio.find(class_=\"p13n-sc-price\").string\n",
    "    \n",
    "        # Copiem les característiques de cada llibre en una línea del CSV final, utilitzant \";\" com a separador\n",
    "        linea = nom + \";\" + autor + \";\" + puntuacio + \";\" + num_resenyes + \";\" + categoria + \";\" + preu\n",
    "        llista_llibres.append(linea)\n",
    "\n",
    "# Escrivim un fitxer csv amb les dades dels llibres més venuts d'amazon\n",
    "with open('llibres.csv', 'w', newline='') as csvFile:\n",
    "    csvFile.write(\"Nom;Autor;Puntuacio;Num_resenyes;Categoria;Preu\\n\")\n",
    "    for llibre in llista_llibres:\n",
    "        csvFile.write(llibre)\n",
    "        csvFile.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
